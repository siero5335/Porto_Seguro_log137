{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from multiprocessing import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Regularized Greedy Forest\n",
    "from rgf.sklearn import RGFClassifier     # https://github.com/fukatani/rgf_python\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data\n",
    "train = pd.read_csv('/Users/siero5335/Desktop/Safe Driver Prediction/train.csv')\n",
    "test = pd.read_csv('/Users/siero5335/Desktop/Safe Driver Prediction/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ps_ind_16_bin ps_ind_17_bin\n",
      "ps_ind_16_bin ps_ind_18_bin\n",
      "ps_ind_17_bin ps_ind_16_bin\n",
      "ps_ind_17_bin ps_ind_18_bin\n",
      "ps_ind_18_bin ps_ind_16_bin\n",
      "ps_ind_18_bin ps_ind_17_bin\n"
     ]
    }
   ],
   "source": [
    "id_test = test['id'].values\n",
    "target_train = train['target'].values\n",
    "\n",
    "\n",
    "train.drop(['id','target'],axis=1,inplace=True)\n",
    "test.drop(['id'],axis=1,inplace=True)\n",
    "\n",
    "train['ps_ind_0609_bin'] = train.apply(lambda x: 1 if x['ps_ind_06_bin'] == 1 else (2 if x['ps_ind_07_bin'] == 1 else \n",
    "(\n",
    "3 if x['ps_ind_08_bin'] == 1 else (4 if x['ps_ind_09_bin'] == 1 else 5)\n",
    "\n",
    ")), axis = 1)\n",
    "\n",
    "test['ps_ind_0609_bin'] = test.apply(lambda x: 1 if x['ps_ind_06_bin'] == 1 else (2 if x['ps_ind_07_bin'] == 1 else \n",
    "(\n",
    "3 if x['ps_ind_08_bin'] == 1 else (4 if x['ps_ind_09_bin'] == 1 else 5)\n",
    "\n",
    ")), axis = 1)\n",
    "\n",
    "train.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1, inplace = True)\n",
    "\n",
    "test.drop(['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin'], axis = 1, inplace = True)\n",
    "\n",
    "train['ps_car_13'] = (train['ps_car_13']*train['ps_car_13']* 48400).round(0)\n",
    "\n",
    "test['ps_car_13'] = (test['ps_car_13']*test['ps_car_13']* 48400).round(0)\n",
    "\n",
    "train['ps_car_12'] = (train['ps_car_12']*train['ps_car_12']).round(4) * 10000\n",
    "\n",
    "test['ps_car_12'] = (test['ps_car_12']*test['ps_car_12']).round(4) * 10000\n",
    "\n",
    "for c in train[[c for c in train.columns if 'bin' in c]].columns:\n",
    "    for cc in train[[c for c in train.columns if 'bin' in c]].columns:\n",
    "            if train[train[cc] * train[c] == 0].shape[0] == train.shape[0]:\n",
    "                print(c, cc)\n",
    "\n",
    "train['ps_ind_161718_bin'] = train.apply(lambda x: 1 if x['ps_ind_16_bin'] == 1 else\n",
    "                                        (2 if x['ps_ind_17_bin'] == 1 else 3), axis = 1\n",
    "                                        )\n",
    "\n",
    "test['ps_ind_161718_bin'] = test.apply(lambda x: 1 if x['ps_ind_16_bin'] == 1 else\n",
    "                                        (2 if x['ps_ind_17_bin'] == 1 else 3), axis = 1\n",
    "                                        )\n",
    "\n",
    "train.drop(['ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin'], axis = 1, inplace = True)\n",
    "\n",
    "test.drop(['ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Great Recovery from Pascal's materpiece\n",
    "\n",
    "def recon(reg):\n",
    "    integer = int(np.round((40*reg)**2)) \n",
    "    for a in range(32):\n",
    "        if (integer - a) % 31 == 0:\n",
    "            A = a\n",
    "    M = (integer - A)//31\n",
    "    return A, M\n",
    "train['ps_reg_A'] = train['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "train['ps_reg_M'] = train['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "train['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "train['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "test['ps_reg_A'] = test['ps_reg_03'].apply(lambda x: recon(x)[0])\n",
    "test['ps_reg_M'] = test['ps_reg_03'].apply(lambda x: recon(x)[1])\n",
    "test['ps_reg_A'].replace(19,-1, inplace=True)\n",
    "test['ps_reg_M'].replace(51,-1, inplace=True)\n",
    "\n",
    "train['ps_car_13_x_ps_reg_03'] = train['ps_car_13'] * train['ps_reg_03']\n",
    "test['ps_car_13_x_ps_reg_03'] = test['ps_car_13'] * test['ps_reg_03']\n",
    "\n",
    "# Columns -> binary decoded.\n",
    "\n",
    "tmp  = train['ps_calc_15_bin'] * 32 + train['ps_calc_16_bin'] * 16 + train['ps_calc_17_bin'] * 8\n",
    "tmp += train['ps_calc_18_bin'] * 4 + train['ps_calc_19_bin'] * 2 + train['ps_calc_20_bin'] * 1\n",
    "\n",
    "tmp2 = [5, 22, 9, 32, 13, 38, 20, 47, 2, 19, 8, 30, 10, 35, 17, 45, 1,\n",
    "        15, 4, 24, 7, 29, 14, 40, 0, 12, 3, 21, 6, 26, 11, 36, 27, 52,\n",
    "        37, 57, 42, 60, 51, 63, 23, 49, 34, 56, 39, 59, 48, 62, 18, 46,\n",
    "        28, 53, 33, 55, 44, 61, 16, 43, 25, 50, 31, 54, 41, 58]\n",
    "tmp2 = pd.Series(tmp2)\n",
    "\n",
    "train['ps_calc_15_16_17_18_19_20'] = tmp.map(tmp2)\n",
    "\n",
    "\n",
    "tmp3  = test['ps_calc_15_bin'] * 32 + test['ps_calc_16_bin'] * 16 + test['ps_calc_17_bin'] * 8\n",
    "tmp3 += test['ps_calc_18_bin'] * 4 + test['ps_calc_19_bin'] * 2 + test['ps_calc_20_bin'] * 1\n",
    "\n",
    "tmp4 = [5, 22, 9, 32, 13, 38, 20, 47, 2, 19, 8, 30, 10, 35, 17, 45, 1,\n",
    "        15, 4, 24, 7, 29, 14, 40, 0, 12, 3, 21, 6, 26, 11, 36, 27, 52,\n",
    "        37, 57, 42, 60, 51, 63, 23, 49, 34, 56, 39, 59, 48, 62, 18, 46,\n",
    "        28, 53, 33, 55, 44, 61, 16, 43, 25, 50, 31, 54, 41, 58]\n",
    "tmp4 = pd.Series(tmp4)\n",
    "\n",
    "test['ps_calc_15_16_17_18_19_20'] = tmp3.map(tmp4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from olivier\n",
    "train_features = [\n",
    "    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n",
    "\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n",
    "\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n",
    "\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n",
    "\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n",
    "\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n",
    "\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n",
    "\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n",
    "\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n",
    "\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n",
    "\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n",
    "\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n",
    "\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n",
    "\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n",
    "\t\"ps_ind_161718_bin\",  #        :  475.37 / shadow   34.17\n",
    "\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n",
    "\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n",
    "\t\"ps_ind_0609_bin\",  #        :  370.97 / shadow   36.13\n",
    "\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n",
    "\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n",
    "\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n",
    "\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n",
    "\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n",
    "\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n",
    "\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n",
    "\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n",
    "\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n",
    "\t\"ps_car_13_x_ps_reg_03\",  \n",
    "    \"ps_calc_15_16_17_18_19_20\" #  \n",
    "]\n",
    "# add combinations\n",
    "combs = [\n",
    "    ('ps_reg_01', 'ps_car_02_cat'),  \n",
    "    ('ps_reg_01', 'ps_car_04_cat'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current feature                                 ps_reg_01_plus_ps_car_02_cat    1 in   0.0\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "current feature                                 ps_reg_01_plus_ps_car_04_cat    2 in   0.1\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "\r",
      "(595212, 218) (892816, 218)\n"
     ]
    }
   ],
   "source": [
    "train = train[train_features]\n",
    "test = test[train_features]\n",
    "\n",
    "start = time.time()\n",
    "for n_c, (f1, f2) in enumerate(combs):\n",
    "    name1 = f1 + \"_plus_\" + f2\n",
    "    print('current feature %60s %4d in %5.1f'\n",
    "          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n",
    "    print('\\r' * 75, end='')\n",
    "    train[name1] = train[f1].apply(lambda x: str(x)) + \"_\" + train[f2].apply(lambda x: str(x))\n",
    "    test[name1] = test[f1].apply(lambda x: str(x)) + \"_\" + test[f2].apply(lambda x: str(x))\n",
    "    # Label Encode\n",
    "    lbl = LabelEncoder()\n",
    "    lbl.fit(list(train[name1].values) + list(test[name1].values))\n",
    "    train[name1] = lbl.transform(list(train[name1].values))\n",
    "    test[name1] = lbl.transform(list(test[name1].values))\n",
    "\n",
    "    train_features.append(name1)\n",
    "    \n",
    "\n",
    "\n",
    "cat_features = [a for a in train.columns if a.endswith('cat')]\n",
    "\n",
    "for column in cat_features:\n",
    "\ttemp = pd.get_dummies(pd.Series(train[column]))\n",
    "\ttrain = pd.concat([train,temp],axis=1)\n",
    "\ttrain = train.drop([column],axis=1)\n",
    "    \n",
    "for column in cat_features:\n",
    "\ttemp = pd.get_dummies(pd.Series(test[column]))\n",
    "\ttest = pd.concat([test,temp],axis=1)\n",
    "\ttest = test.drop([column],axis=1)\n",
    "\n",
    "\n",
    "print(train.values.shape, test.values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2017).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                y_holdout = y[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                cross_score = cross_val_score(clf, X_train, y_train, cv=self.n_splits, scoring='roc_auc')\n",
    "                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "            print(\"     Model score: %.5f\\n\" % roc_auc_score(y, S_train[:,i]))\n",
    "\n",
    "        self.base_preds = S_test\n",
    "        \n",
    "        # Log odds transformation\n",
    "        almost_zero = 1e-12\n",
    "        almost_one = 1 - almost_zero  # To avoid division by zero\n",
    "        S_train[S_train>almost_one] = almost_one\n",
    "        S_train[S_train<almost_zero] = almost_zero\n",
    "        S_train = np.log(S_train/(1-S_train))\n",
    "        S_test[S_test>almost_one] = almost_one\n",
    "        S_test[S_test<almost_zero] = almost_zero\n",
    "        S_test = np.log(S_test/(1-S_test))\n",
    "        \n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=self.n_splits, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        print( 'Coefficients:', self.stacker.coef_ )\n",
    "\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM params\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.02\n",
    "lgb_params['n_estimators'] = 650\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['random_state'] = 99\n",
    "\n",
    "\n",
    "lgb_params2 = {}\n",
    "lgb_params2['n_estimators'] = 1090\n",
    "lgb_params2['learning_rate'] = 0.02\n",
    "lgb_params2['colsample_bytree'] = 0.3   \n",
    "lgb_params2['subsample'] = 0.7\n",
    "lgb_params2['subsample_freq'] = 2\n",
    "lgb_params2['num_leaves'] = 16\n",
    "lgb_params2['random_state'] = 99\n",
    "\n",
    "\n",
    "lgb_params3 = {}\n",
    "lgb_params3['n_estimators'] = 1100\n",
    "lgb_params3['max_depth'] = 4\n",
    "lgb_params3['learning_rate'] = 0.02\n",
    "lgb_params3['random_state'] = 99\n",
    "\n",
    "lgb_params4 = {}\n",
    "lgb_params4['learning_rate'] = 0.02\n",
    "lgb_params4['n_estimators'] = 650\n",
    "lgb_params4['max_bin'] = 10\n",
    "lgb_params4['subsample'] = 0.8\n",
    "lgb_params4['subsample_freq'] = 10\n",
    "lgb_params4['colsample_bytree'] = 0.8   \n",
    "lgb_params4['min_child_samples'] = 500\n",
    "lgb_params4['random_state'] = 71\n",
    "lgb_params['reg_lambda'] = 1.3\n",
    "\n",
    "lgb_params5 = {}\n",
    "lgb_params5['n_estimators'] = 1090\n",
    "lgb_params5['learning_rate'] = 0.02\n",
    "lgb_params5['colsample_bytree'] = 0.3   \n",
    "lgb_params5['subsample'] = 0.7\n",
    "lgb_params5['subsample_freq'] = 2\n",
    "lgb_params5['num_leaves'] = 16\n",
    "lgb_params5['random_state'] = 71\n",
    "lgb_params['reg_lambda'] = 1.3\n",
    "\n",
    "lgb_params6 = {}\n",
    "lgb_params6['n_estimators'] = 1100\n",
    "lgb_params6['max_depth'] = 4\n",
    "lgb_params6['learning_rate'] = 0.02\n",
    "lgb_params6['random_state'] = 71\n",
    "lgb_params['reg_lambda'] = 1.3\n",
    "lgb_params['subsample'] = 0.8\n",
    "\n",
    "# XGBoost params\n",
    "xgb_params1 = {}\n",
    "xgb_params1['objective'] = 'binary:logistic'\n",
    "xgb_params1['learning_rate'] = 0.02\n",
    "xgb_params1['n_estimators'] = 1100\n",
    "xgb_params1['max_depth'] = 4\n",
    "xgb_params1['subsample'] = 0.8\n",
    "xgb_params1['colsample_bytree'] = 0.8 \n",
    "xgb_params1['min_child_weight'] = 2.4073000000000002\n",
    "xgb_params1['reg_alpha'] = 8.0701999999999998\n",
    "xgb_params1['seed'] = 71\n",
    "xgb_params1['gamma'] = 0.15110000000000001\n",
    "xgb_params1['reg_lambda'] =  2.0125999999999999\n",
    "xgb_params1['scale_pos_weight'] =  2.2281\n",
    "\n",
    "xgb_params2 = {}\n",
    "xgb_params2['objective'] = 'binary:logistic'\n",
    "xgb_params2['learning_rate'] = 0.02\n",
    "xgb_params2['n_estimators'] = 1100\n",
    "xgb_params2['max_depth'] = 4\n",
    "xgb_params2['subsample'] = 0.8\n",
    "xgb_params2['colsample_bytree'] = 0.8 \n",
    "xgb_params2['min_child_weight'] = 2.4073000000000002\n",
    "xgb_params2['reg_alpha'] = 8.0701999999999998\n",
    "xgb_params2['seed'] = 99\n",
    "xgb_params2['gamma'] = 0.15110000000000001\n",
    "xgb_params2['reg_lambda'] = 2.0125999999999999\n",
    "xgb_params2['scale_pos_weight'] =  2.2281\n",
    "\n",
    "xgb_params3 = {}\n",
    "xgb_params3['objective'] = 'binary:logistic'\n",
    "xgb_params3['learning_rate'] = 0.02\n",
    "xgb_params3['n_estimators'] = 1100\n",
    "xgb_params3['max_depth'] = 4\n",
    "xgb_params3['subsample'] = 0.8\n",
    "xgb_params3['colsample_bytree'] = 0.8 \n",
    "xgb_params3['min_child_weight'] = 2.4073000000000002\n",
    "xgb_params3['reg_alpha'] = 8.0701999999999998\n",
    "xgb_params3['seed'] = 114514\n",
    "xgb_params3['gamma'] = 0.15110000000000001\n",
    "xgb_params3['reg_lambda'] = 2.0125999999999999\n",
    "xgb_params3['scale_pos_weight'] =  2.2281\n",
    "\n",
    "# Regularized Greedy Forest params\n",
    "rgf_params = {}\n",
    "rgf_params['max_leaf'] = 2000\n",
    "rgf_params['learning_rate'] = 0.2\n",
    "rgf_params['algorithm'] = \"RGF_Sib\"\n",
    "rgf_params['test_interval'] = 100\n",
    "rgf_params['min_samples_leaf'] = 3 \n",
    "rgf_params['reg_depth'] = 1.0\n",
    "rgf_params['l2'] = 0.5  \n",
    "rgf_params['sl2'] = 0.005\n",
    "\n",
    "#CatBoost params\n",
    "cat_params = {}\n",
    "cat_params['iterations'] = 900\n",
    "cat_params['depth'] = 4\n",
    "cat_params['rsm'] = 0.95\n",
    "cat_params['learning_rate'] = 0.03\n",
    "cat_params['l2_leaf_reg'] = 3.5  \n",
    "cat_params['border_count'] = 8\n",
    "cat_params['gradient_iterations'] = 4\n",
    "\n",
    "cat_params2 = {}\n",
    "cat_params2['iterations'] = 900\n",
    "cat_params2['depth'] = 8\n",
    "cat_params2['rsm'] = 0.95\n",
    "cat_params2['learning_rate'] = 0.03\n",
    "cat_params2['l2_leaf_reg'] = 3.5  \n",
    "cat_params2['border_count'] = 8\n",
    "cat_params2['gradient_iterations'] = 4\n",
    "\n",
    "cat_params3 = {}\n",
    "cat_params3['iterations'] = 900\n",
    "cat_params3['depth'] = 10\n",
    "cat_params3['rsm'] = 0.95\n",
    "cat_params3['learning_rate'] = 0.03\n",
    "cat_params3['l2_leaf_reg'] = 3.5  \n",
    "cat_params3['border_count'] = 8\n",
    "cat_params3['gradient_iterations'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier(**cat_params)\n",
    "\n",
    "cat_model2 = CatBoostClassifier(**cat_params2)\n",
    "\n",
    "cat_model3 = CatBoostClassifier(**cat_params3)\n",
    "\n",
    "lgb_model = LGBMClassifier(**lgb_params)\n",
    "\n",
    "lgb_model2 = LGBMClassifier(**lgb_params2)\n",
    "\n",
    "lgb_model3 = LGBMClassifier(**lgb_params3)\n",
    "\n",
    "lgb_model4 = LGBMClassifier(**lgb_params4)\n",
    "\n",
    "lgb_model5 = LGBMClassifier(**lgb_params5)\n",
    "\n",
    "lgb_model6 = LGBMClassifier(**lgb_params6)\n",
    "\n",
    "xgb_model1 = XGBClassifier(**xgb_params1)\n",
    "\n",
    "xgb_model2 = XGBClassifier(**xgb_params2)\n",
    "\n",
    "xgb_model3 = XGBClassifier(**xgb_params3)\n",
    "\n",
    "rgf_model = RGFClassifier(**rgf_params)\n",
    "\n",
    "log_model = LogisticRegression(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3518> fold 1\n",
      "    cross_score: 0.63895\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3518> fold 2\n",
      "    cross_score: 0.63785\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3518> fold 3\n",
      "    cross_score: 0.63736\n",
      "     Model score: 0.63946\n",
      "\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3048> fold 1\n",
      "    cross_score: 0.64037\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3048> fold 2\n",
      "    cross_score: 0.63956\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3048> fold 3\n",
      "    cross_score: 0.63970\n",
      "     Model score: 0.64211\n",
      "\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3358> fold 1\n",
      "    cross_score: 0.63835\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3358> fold 2\n",
      "    cross_score: 0.63854\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1317d3358> fold 3\n",
      "    cross_score: 0.63940\n",
      "     Model score: 0.64127\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63979\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.63964\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.64133\n",
      "     Model score: 0.64237\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63940\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.64044\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.64058\n",
      "     Model score: 0.64203\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63807\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.63888\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.63842\n",
      "     Model score: 0.64070\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63911\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.63939\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.63978\n",
      "     Model score: 0.64162\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63959\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.64038\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.64015\n",
      "     Model score: 0.64188\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63797\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.63917\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.63828\n",
      "     Model score: 0.64052\n",
      "\n",
      "Fit XGBClassifier fold 1\n",
      "    cross_score: 0.64034\n",
      "Fit XGBClassifier fold 2\n",
      "    cross_score: 0.64035\n",
      "Fit XGBClassifier fold 3\n",
      "    cross_score: 0.64108\n",
      "     Model score: 0.64234\n",
      "\n",
      "Fit XGBClassifier fold 1\n",
      "    cross_score: 0.64017\n",
      "Fit XGBClassifier fold 2\n",
      "    cross_score: 0.64066\n",
      "Fit XGBClassifier fold 3\n",
      "    cross_score: 0.64064\n",
      "     Model score: 0.64249\n",
      "\n",
      "Fit XGBClassifier fold 1\n",
      "    cross_score: 0.63960\n",
      "Fit XGBClassifier fold 2\n",
      "    cross_score: 0.64049\n",
      "Fit XGBClassifier fold 3\n",
      "    cross_score: 0.64079\n",
      "     Model score: 0.64245\n",
      "\n",
      "Stacker score: 0.64351\n",
      "Coefficients: [[-0.01208463  0.32643524  0.04969892  0.28592475  0.09521047  0.05445084\n",
      "   0.04448882  0.13178477 -0.10010624 -0.00073447 -0.07471414  0.23928624]]\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(fit_intercept=False)\n",
    "\n",
    "stack = Ensemble(n_splits=3,\n",
    "        stacker = log_model,\n",
    "        base_models = (cat_model, cat_model2, cat_model3, lgb_model, lgb_model2, lgb_model3, lgb_model4, lgb_model5, lgb_model6,\n",
    "                                xgb_model1, xgb_model2, xgb_model3))        \n",
    "        \n",
    "y_pred = stack.fit_predict(train, target_train, test)        \n",
    "\n",
    "\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_pred\n",
    "sub.to_csv('stacked_12_lgb_xgb_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
