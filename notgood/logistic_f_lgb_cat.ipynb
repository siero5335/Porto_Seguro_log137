{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score ,roc_curve,accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from multiprocessing import *\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import time\n",
    "import gc\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "\n",
    "# Regularized Greedy Forest\n",
    "from rgf.sklearn import RGFClassifier     # https://github.com/fukatani/rgf_python\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load Data\n",
    "train = pd.read_csv('/Users/siero5335/Desktop/Safe Driver Prediction/train.csv',na_values=-1)\n",
    "test = pd.read_csv('/Users/siero5335/Desktop/Safe Driver Prediction/test.csv',na_values=-1)\n",
    "id_test = test['id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(595212, 39)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_cal = train.columns[train.columns.str.startswith('ps_calc')] \n",
    "train = train.drop(ps_cal,axis =1)\n",
    "test = test.drop(ps_cal,axis=1)\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_value(df):\n",
    "    col = df.columns\n",
    "    for i in col:\n",
    "        if df[i].isnull().sum()>0:\n",
    "            df[i].fillna(df[i].mode()[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_value(train)\n",
    "missing_value(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Unique value of \"id\" is \"595212\" \n",
      "\n",
      " Unique value of \"target\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_01\" is \"8\" \n",
      "\n",
      " Unique value of \"ps_ind_02_cat\" is \"4\" \n",
      "\n",
      " Unique value of \"ps_ind_03\" is \"12\" \n",
      "\n",
      " Unique value of \"ps_ind_04_cat\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_05_cat\" is \"7\" \n",
      "\n",
      " Unique value of \"ps_ind_06_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_07_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_08_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_09_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_10_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_11_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_12_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_13_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_14\" is \"5\" \n",
      "\n",
      " Unique value of \"ps_ind_15\" is \"14\" \n",
      "\n",
      " Unique value of \"ps_ind_16_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_17_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_ind_18_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_reg_01\" is \"10\" \n",
      "\n",
      " Unique value of \"ps_reg_02\" is \"19\" \n",
      "\n",
      " Unique value of \"ps_reg_03\" is \"5012\" \n",
      "\n",
      " Unique value of \"ps_car_01_cat\" is \"12\" \n",
      "\n",
      " Unique value of \"ps_car_02_cat\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_car_03_cat\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_car_04_cat\" is \"10\" \n",
      "\n",
      " Unique value of \"ps_car_05_cat\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_car_06_cat\" is \"18\" \n",
      "\n",
      " Unique value of \"ps_car_07_cat\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_car_08_cat\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_car_09_cat\" is \"5\" \n",
      "\n",
      " Unique value of \"ps_car_10_cat\" is \"3\" \n",
      "\n",
      " Unique value of \"ps_car_11_cat\" is \"104\" \n",
      "\n",
      " Unique value of \"ps_car_11\" is \"4\" \n",
      "\n",
      " Unique value of \"ps_car_12\" is \"183\" \n",
      "\n",
      " Unique value of \"ps_car_13\" is \"70482\" \n",
      "\n",
      " Unique value of \"ps_car_14\" is \"849\" \n",
      "\n",
      " Unique value of \"ps_car_15\" is \"15\" \n",
      "\n",
      " Unique value of \"ps_calc_01\" is \"10\" \n",
      "\n",
      " Unique value of \"ps_calc_02\" is \"10\" \n",
      "\n",
      " Unique value of \"ps_calc_03\" is \"10\" \n",
      "\n",
      " Unique value of \"ps_calc_04\" is \"6\" \n",
      "\n",
      " Unique value of \"ps_calc_05\" is \"7\" \n",
      "\n",
      " Unique value of \"ps_calc_06\" is \"11\" \n",
      "\n",
      " Unique value of \"ps_calc_07\" is \"10\" \n",
      "\n",
      " Unique value of \"ps_calc_08\" is \"11\" \n",
      "\n",
      " Unique value of \"ps_calc_09\" is \"8\" \n",
      "\n",
      " Unique value of \"ps_calc_10\" is \"26\" \n",
      "\n",
      " Unique value of \"ps_calc_11\" is \"20\" \n",
      "\n",
      " Unique value of \"ps_calc_12\" is \"11\" \n",
      "\n",
      " Unique value of \"ps_calc_13\" is \"14\" \n",
      "\n",
      " Unique value of \"ps_calc_14\" is \"24\" \n",
      "\n",
      " Unique value of \"ps_calc_15_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_calc_16_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_calc_17_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_calc_18_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_calc_19_bin\" is \"2\" \n",
      "\n",
      " Unique value of \"ps_calc_20_bin\" is \"2\" \n"
     ]
    }
   ],
   "source": [
    "def uniq(df):\n",
    "    col = df.columns\n",
    "    for i in col:\n",
    "        print('\\n Unique value of \"{}\" is \"{}\" '.format(i,df[i].nunique()))\n",
    "        #print(df[i].unique())\n",
    "uniq(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_type(df):\n",
    "    col = df.columns\n",
    "    for i in col:\n",
    "        if df[i].nunique()<=104:\n",
    "            df[i] = df[i].astype('category')\n",
    "category_type(train)\n",
    "category_type(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_ind_02_cat', 'ps_ind_04_cat', 'ps_ind_05_cat', 'ps_car_01_cat', 'ps_car_02_cat', 'ps_car_03_cat', 'ps_car_04_cat', 'ps_car_05_cat', 'ps_car_06_cat', 'ps_car_07_cat', 'ps_car_08_cat', 'ps_car_09_cat', 'ps_car_10_cat', 'ps_car_11_cat']\n"
     ]
    }
   ],
   "source": [
    "cat_col = [col for col in train.columns if '_cat' in col]\n",
    "print(cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ps_ind_06_bin', 'ps_ind_07_bin', 'ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_16_bin', 'ps_ind_17_bin', 'ps_ind_18_bin', 'ps_calc_15_bin', 'ps_calc_16_bin', 'ps_calc_17_bin', 'ps_calc_18_bin', 'ps_calc_19_bin', 'ps_calc_20_bin']\n"
     ]
    }
   ],
   "source": [
    "bin_col = [col for col in train.columns if 'bin' in col]\n",
    "print(bin_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target',\n",
       " 'ps_ind_01',\n",
       " 'ps_ind_03',\n",
       " 'ps_ind_14',\n",
       " 'ps_ind_15',\n",
       " 'ps_reg_01',\n",
       " 'ps_reg_02',\n",
       " 'ps_car_11',\n",
       " 'ps_car_15']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot_cat_col = list(train.select_dtypes(include=['category']).columns)\n",
    "\n",
    "other_cat_col = [c for c in tot_cat_col if c not in cat_col+ bin_col]\n",
    "other_cat_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ps_reg_03', 'ps_car_12', 'ps_car_13', 'ps_car_14', 'ps_car_15']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_col = [c for c in train.columns if c not in tot_cat_col]\n",
    "num_col.append('ps_car_15')\n",
    "train['ps_car_15'] = train['ps_car_15'].astype('float32')\n",
    "test['ps_car_15'] = test['ps_car_15'].astype('float32')\n",
    "num_col.remove('id')\n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final categorical columns to be consider\n",
    "tot_cat_col.remove('ps_car_15')\n",
    "tot_cat_col.remove('target')\n",
    "train['ps_car_15'] = train['ps_car_15'].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08484029175 1.54909582495\n",
      "0.4183300133 1.8521946442\n",
      "0.190569415 0.525658351\n",
      "0.3155946768 0.5656854249\n",
      "0.31788087655 1.25917611615\n",
      "0.448300509774 1.61761689551\n",
      "0.2891566485 0.4608812941\n",
      "0.2887905816 0.5234500931\n",
      "1.66274082661 4.77123749256\n",
      "0.0 3.7416574955\n"
     ]
    }
   ],
   "source": [
    "def outlier(df,columns):\n",
    "    for i in columns:\n",
    "        quartile_1,quartile_3 = np.percentile(df[i],[25,75])\n",
    "        quartile_f,quartile_l = np.percentile(df[i],[1,99])\n",
    "        IQR = quartile_3-quartile_1\n",
    "        lower_bound = quartile_1 - (1.5*IQR)\n",
    "        upper_bound = quartile_3 + (1.5*IQR)\n",
    "        print(lower_bound,upper_bound)\n",
    "        print(quartile_f,quartile_l)\n",
    "        \n",
    "        df[i].loc[df[i] < lower_bound] = quartile_f\n",
    "        df[i].loc[df[i] > upper_bound] = quartile_l\n",
    "        \n",
    "outlier(train,num_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OHE(df1,df2,column):\n",
    "    cat_col = column\n",
    "    #cat_col = df.select_dtypes(include =['category']).columns\n",
    "    len_df1 = df1.shape[0]\n",
    "    \n",
    "    df = pd.concat([df1,df2],ignore_index=True)\n",
    "    c2,c3 = [],{}\n",
    "    \n",
    "    print('Categorical feature',len(column))\n",
    "    for c in cat_col:\n",
    "        if df[c].nunique()>2 :\n",
    "            c2.append(c)\n",
    "            c3[c] = 'ohe_'+c\n",
    "    \n",
    "    df = pd.get_dummies(df, prefix=c3, columns=c2,drop_first=True)\n",
    "\n",
    "    df1 = df.loc[:len_df1-1]\n",
    "    df2 = df.loc[len_df1:]\n",
    "    print(df1.shape)\n",
    "    print(df2.shape)\n",
    "    return df1,df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical feature 32\n",
      "(595212, 244)\n",
      "(892816, 244)\n"
     ]
    }
   ],
   "source": [
    "train1,test1 = OHE(train,test,tot_cat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train1.drop(['target','id'],axis=1)\n",
    "target_train = train1['target'].astype('category')\n",
    "test = test1.drop(['target','id'],axis=1)\n",
    "del train1,test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ensemble(object):\n",
    "    def __init__(self, n_splits, stacker, base_models):\n",
    "        self.n_splits = n_splits\n",
    "        self.stacker = stacker\n",
    "        self.base_models = base_models\n",
    "\n",
    "    def fit_predict(self, X, y, T):\n",
    "        X = np.array(X)\n",
    "        y = np.array(y)\n",
    "        T = np.array(T)\n",
    "\n",
    "        folds = list(StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=2017).split(X, y))\n",
    "\n",
    "        S_train = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        S_test = np.zeros((T.shape[0], len(self.base_models)))\n",
    "        for i, clf in enumerate(self.base_models):\n",
    "\n",
    "            S_test_i = np.zeros((T.shape[0], self.n_splits))\n",
    "\n",
    "            for j, (train_idx, test_idx) in enumerate(folds):\n",
    "                X_train = X[train_idx]\n",
    "                y_train = y[train_idx]\n",
    "                X_holdout = X[test_idx]\n",
    "                y_holdout = y[test_idx]\n",
    "\n",
    "                print (\"Fit %s fold %d\" % (str(clf).split('(')[0], j+1))\n",
    "                clf.fit(X_train, y_train)\n",
    "                cross_score = cross_val_score(clf, X_train, y_train, cv=self.n_splits, scoring='roc_auc')\n",
    "                print(\"    cross_score: %.5f\" % (cross_score.mean()))\n",
    "                y_pred = clf.predict_proba(X_holdout)[:,1]                \n",
    "\n",
    "                S_train[test_idx, i] = y_pred\n",
    "                S_test_i[:, j] = clf.predict_proba(T)[:,1]\n",
    "            S_test[:, i] = S_test_i.mean(axis=1)\n",
    "\n",
    "            print(\"     Model score: %.5f\\n\" % roc_auc_score(y, S_train[:,i]))\n",
    "\n",
    "        self.base_preds = S_test\n",
    "        \n",
    "        # Log odds transformation\n",
    "        almost_zero = 1e-12\n",
    "        almost_one = 1 - almost_zero  # To avoid division by zero\n",
    "        S_train[S_train>almost_one] = almost_one\n",
    "        S_train[S_train<almost_zero] = almost_zero\n",
    "        S_train = np.log(S_train/(1-S_train))\n",
    "        S_test[S_test>almost_one] = almost_one\n",
    "        S_test[S_test<almost_zero] = almost_zero\n",
    "        S_test = np.log(S_test/(1-S_test))\n",
    "        \n",
    "        results = cross_val_score(self.stacker, S_train, y, cv=self.n_splits, scoring='roc_auc')\n",
    "        print(\"Stacker score: %.5f\" % (results.mean()))\n",
    "\n",
    "        self.stacker.fit(S_train, y)\n",
    "        print( 'Coefficients:', self.stacker.coef_ )\n",
    "\n",
    "        res = self.stacker.predict_proba(S_test)[:,1]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM params\n",
    "lgb_params = {}\n",
    "lgb_params['learning_rate'] = 0.02\n",
    "lgb_params['n_estimators'] = 650\n",
    "lgb_params['max_bin'] = 10\n",
    "lgb_params['subsample'] = 0.8\n",
    "lgb_params['subsample_freq'] = 10\n",
    "lgb_params['colsample_bytree'] = 0.8   \n",
    "lgb_params['min_child_samples'] = 500\n",
    "lgb_params['random_state'] = 99\n",
    "\n",
    "\n",
    "lgb_params2 = {}\n",
    "lgb_params2['n_estimators'] = 1090\n",
    "lgb_params2['learning_rate'] = 0.02\n",
    "lgb_params2['colsample_bytree'] = 0.3   \n",
    "lgb_params2['subsample'] = 0.7\n",
    "lgb_params2['subsample_freq'] = 2\n",
    "lgb_params2['num_leaves'] = 16\n",
    "lgb_params2['random_state'] = 99\n",
    "\n",
    "\n",
    "lgb_params3 = {}\n",
    "lgb_params3['n_estimators'] = 1100\n",
    "lgb_params3['max_depth'] = 4\n",
    "lgb_params3['learning_rate'] = 0.02\n",
    "lgb_params3['random_state'] = 99\n",
    "\n",
    "lgb_params4 = {}\n",
    "lgb_params4['learning_rate'] = 0.02\n",
    "lgb_params4['n_estimators'] = 650\n",
    "lgb_params4['max_bin'] = 10\n",
    "lgb_params4['subsample'] = 0.8\n",
    "lgb_params4['subsample_freq'] = 10\n",
    "lgb_params4['colsample_bytree'] = 0.8   \n",
    "lgb_params4['min_child_samples'] = 500\n",
    "lgb_params4['random_state'] = 71\n",
    "lgb_params['reg_lambda'] = 1.3\n",
    "\n",
    "lgb_params5 = {}\n",
    "lgb_params5['n_estimators'] = 1090\n",
    "lgb_params5['learning_rate'] = 0.02\n",
    "lgb_params5['colsample_bytree'] = 0.3   \n",
    "lgb_params5['subsample'] = 0.7\n",
    "lgb_params5['subsample_freq'] = 2\n",
    "lgb_params5['num_leaves'] = 16\n",
    "lgb_params5['random_state'] = 71\n",
    "lgb_params['reg_lambda'] = 1.3\n",
    "\n",
    "lgb_params6 = {}\n",
    "lgb_params6['n_estimators'] = 1100\n",
    "lgb_params6['max_depth'] = 4\n",
    "lgb_params6['learning_rate'] = 0.02\n",
    "lgb_params6['random_state'] = 71\n",
    "lgb_params['reg_lambda'] = 1.3\n",
    "lgb_params['subsample'] = 0.8\n",
    "\n",
    "# XGBoost params\n",
    "xgb_params1 = {}\n",
    "xgb_params1['objective'] = 'binary:logistic'\n",
    "xgb_params1['learning_rate'] = 0.02\n",
    "xgb_params1['n_estimators'] = 1100\n",
    "xgb_params1['max_depth'] = 4\n",
    "xgb_params1['subsample'] = 0.8\n",
    "xgb_params1['colsample_bytree'] = 0.8 \n",
    "xgb_params1['min_child_weight'] = 2.4073000000000002\n",
    "xgb_params1['reg_alpha'] = 8.0701999999999998\n",
    "xgb_params1['seed'] = 71\n",
    "xgb_params1['gamma'] = 0.15110000000000001\n",
    "xgb_params1['reg_lambda'] =  2.0125999999999999\n",
    "xgb_params1['scale_pos_weight'] =  2.2281\n",
    "\n",
    "xgb_params2 = {}\n",
    "xgb_params2['objective'] = 'binary:logistic'\n",
    "xgb_params2['learning_rate'] = 0.02\n",
    "xgb_params2['n_estimators'] = 1100\n",
    "xgb_params2['max_depth'] = 4\n",
    "xgb_params2['subsample'] = 0.8\n",
    "xgb_params2['colsample_bytree'] = 0.8 \n",
    "xgb_params2['min_child_weight'] = 2.4073000000000002\n",
    "xgb_params2['reg_alpha'] = 8.0701999999999998\n",
    "xgb_params2['seed'] = 99\n",
    "xgb_params2['gamma'] = 0.15110000000000001\n",
    "xgb_params2['reg_lambda'] = 2.0125999999999999\n",
    "xgb_params2['scale_pos_weight'] =  2.2281\n",
    "\n",
    "xgb_params3 = {}\n",
    "xgb_params3['objective'] = 'binary:logistic'\n",
    "xgb_params3['learning_rate'] = 0.02\n",
    "xgb_params3['n_estimators'] = 1100\n",
    "xgb_params3['max_depth'] = 4\n",
    "xgb_params3['subsample'] = 0.8\n",
    "xgb_params3['colsample_bytree'] = 0.8 \n",
    "xgb_params3['min_child_weight'] = 2.4073000000000002\n",
    "xgb_params3['reg_alpha'] = 8.0701999999999998\n",
    "xgb_params3['seed'] = 114514\n",
    "xgb_params3['gamma'] = 0.15110000000000001\n",
    "xgb_params3['reg_lambda'] = 2.0125999999999999\n",
    "xgb_params3['scale_pos_weight'] =  2.2281\n",
    "\n",
    "# Regularized Greedy Forest params\n",
    "rgf_params = {}\n",
    "rgf_params['max_leaf'] = 2000\n",
    "rgf_params['learning_rate'] = 0.2\n",
    "rgf_params['algorithm'] = \"RGF_Sib\"\n",
    "rgf_params['test_interval'] = 100\n",
    "rgf_params['min_samples_leaf'] = 3 \n",
    "rgf_params['reg_depth'] = 1.0\n",
    "rgf_params['l2'] = 0.5  \n",
    "rgf_params['sl2'] = 0.005\n",
    "\n",
    "#CatBoost params\n",
    "cat_params = {}\n",
    "cat_params['iterations'] = 900\n",
    "cat_params['depth'] = 4\n",
    "cat_params['rsm'] = 0.95\n",
    "cat_params['learning_rate'] = 0.03\n",
    "cat_params['l2_leaf_reg'] = 3.5  \n",
    "cat_params['border_count'] = 8\n",
    "cat_params['gradient_iterations'] = 4\n",
    "\n",
    "cat_params2 = {}\n",
    "cat_params2['iterations'] = 900\n",
    "cat_params2['depth'] = 8\n",
    "cat_params2['rsm'] = 0.95\n",
    "cat_params2['learning_rate'] = 0.03\n",
    "cat_params2['l2_leaf_reg'] = 3.5  \n",
    "cat_params2['border_count'] = 8\n",
    "cat_params2['gradient_iterations'] = 4\n",
    "\n",
    "cat_params3 = {}\n",
    "cat_params3['iterations'] = 900\n",
    "cat_params3['depth'] = 10\n",
    "cat_params3['rsm'] = 0.95\n",
    "cat_params3['learning_rate'] = 0.03\n",
    "cat_params3['l2_leaf_reg'] = 3.5  \n",
    "cat_params3['border_count'] = 8\n",
    "cat_params3['gradient_iterations'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_model = CatBoostClassifier(**cat_params)\n",
    "\n",
    "cat_model2 = CatBoostClassifier(**cat_params2)\n",
    "\n",
    "cat_model3 = CatBoostClassifier(**cat_params3)\n",
    "\n",
    "lgb_model = LGBMClassifier(**lgb_params)\n",
    "\n",
    "lgb_model2 = LGBMClassifier(**lgb_params2)\n",
    "\n",
    "lgb_model3 = LGBMClassifier(**lgb_params3)\n",
    "\n",
    "lgb_model4 = LGBMClassifier(**lgb_params4)\n",
    "\n",
    "lgb_model5 = LGBMClassifier(**lgb_params5)\n",
    "\n",
    "lgb_model6 = LGBMClassifier(**lgb_params6)\n",
    "\n",
    "xgb_model1 = XGBClassifier(**xgb_params1)\n",
    "\n",
    "xgb_model2 = XGBClassifier(**xgb_params2)\n",
    "\n",
    "xgb_model3 = XGBClassifier(**xgb_params3)\n",
    "\n",
    "rgf_model = RGFClassifier(**rgf_params)\n",
    "\n",
    "log_model = LogisticRegression(fit_intercept=False)\n",
    "\n",
    "ridge_model = Ridge(fit_intercept=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit <catboost.core.CatBoostClassifier object at 0x1ae477160> fold 1\n",
      "    cross_score: 0.63335\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1ae477160> fold 2\n",
      "    cross_score: 0.63336\n",
      "Fit <catboost.core.CatBoostClassifier object at 0x1ae477160> fold 3\n",
      "    cross_score: 0.63217\n",
      "     Model score: 0.63458\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63351\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.63388\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.63388\n",
      "     Model score: 0.63674\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63336\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.63456\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.63462\n",
      "     Model score: 0.63707\n",
      "\n",
      "Fit LGBMClassifier fold 1\n",
      "    cross_score: 0.63225\n",
      "Fit LGBMClassifier fold 2\n",
      "    cross_score: 0.63171\n",
      "Fit LGBMClassifier fold 3\n",
      "    cross_score: 0.63031\n",
      "     Model score: 0.63445\n",
      "\n",
      "Stacker score: 0.63779\n",
      "Coefficients: [[ 0.12554282  0.41200915  0.50906663 -0.04661392]]\n"
     ]
    }
   ],
   "source": [
    "log_model = LogisticRegression(fit_intercept=False)\n",
    "\n",
    "stack = Ensemble(n_splits=3,\n",
    "        stacker = log_model,\n",
    "        base_models = (cat_model, lgb_model, lgb_model2, lgb_model3))        \n",
    "        \n",
    "y_pred = stack.fit_predict(train, target_train, test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = y_pred\n",
    "sub.to_csv('stacked_13_lgb_cat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
